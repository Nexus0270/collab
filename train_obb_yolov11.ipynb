{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff60fce0",
   "metadata": {},
   "source": [
    "# YOLOv11 OBB Model Training - Google Colab\n",
    "\n",
    "This notebook provides a complete workflow for training, validating, and running inference with YOLOv11 Oriented Bounding Box (OBB) models in Google Colab.\n",
    "\n",
    "**Prerequisites:**\n",
    "- Google Colab GPU access (recommended)\n",
    "- A data.yaml file with your OBB dataset configuration\n",
    "- Training images with oriented bounding box annotations\n",
    "\n",
    "**Features:**\n",
    "- Install and manage dependencies\n",
    "- Load pretrained YOLOv11 OBB models\n",
    "- Train models with configurable hyperparameters\n",
    "- Validate trained models\n",
    "- Run inference on images/videos\n",
    "- Visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700273d7",
   "metadata": {},
   "source": [
    "## Section 1: Install and Import Dependencies\n",
    "\n",
    "Install the ultralytics library and import necessary modules for YOLOv11 OBB training in Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a83d81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install ultralytics library\n",
    "!pip install -q ultralytics opencv-python pillow matplotlib\n",
    "\n",
    "# Import required libraries\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import os\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as PILImage\n",
    "import numpy as np\n",
    "\n",
    "print(\"âœ“ Dependencies installed successfully!\")\n",
    "print(\"GPU Available:\", os.system(\"nvidia-smi -L\") == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0740e9",
   "metadata": {},
   "source": [
    "## Section 2: Load Pretrained YOLOv11 OBB Model\n",
    "\n",
    "Load a pretrained YOLOv11 OBB model variant. Choose from:\n",
    "- `yolov11n-obb` - Nano (smallest, fastest)\n",
    "- `yolov11s-obb` - Small\n",
    "- `yolov11m-obb` - Medium\n",
    "- `yolov11l-obb` - Large\n",
    "- `yolov11x-obb` - Extra Large (largest, most accurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16975943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure model variant\n",
    "MODEL_VARIANT = \"yolov11n-obb\"  # Change to yolov11s-obb, yolov11m-obb, etc. for larger models\n",
    "\n",
    "# Load a pretrained YOLOv11 OBB model\n",
    "print(f\"Loading pretrained {MODEL_VARIANT} model...\")\n",
    "model = YOLO(f\"{MODEL_VARIANT}.pt\")\n",
    "\n",
    "print(\"âœ“ Model loaded successfully!\")\n",
    "print(f\"Model: {MODEL_VARIANT}\")\n",
    "print(f\"Model architecture: {model.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa3cf80",
   "metadata": {},
   "source": [
    "## Section 3: Prepare Dataset\n",
    "\n",
    "**Important:** Upload your data.yaml file and ensure your OBB dataset is accessible. Your data.yaml should look like:\n",
    "\n",
    "```yaml\n",
    "path: /path/to/dataset\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "nc: 1  # number of classes\n",
    "names: ['class_name']  # class names\n",
    "```\n",
    "\n",
    "The annotations should be in `.txt` format with OBB format: `<x_center> <y_center> <width> <height> <rotation_angle> <class_id>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bd054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: If using a public dataset or local file\n",
    "# For Colab, you can upload files directly or mount Google Drive\n",
    "\n",
    "# Uncomment to mount Google Drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# Set the path to your data.yaml\n",
    "DATA_YAML_PATH = \"data.yaml\"  # Update this path to your dataset\n",
    "\n",
    "# Verify data.yaml exists\n",
    "if Path(DATA_YAML_PATH).exists():\n",
    "    print(f\"âœ“ Found data.yaml at {DATA_YAML_PATH}\")\n",
    "else:\n",
    "    print(f\"âš  data.yaml not found at {DATA_YAML_PATH}\")\n",
    "    print(\"Please upload your data.yaml file or update the path above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9451fd94",
   "metadata": {},
   "source": [
    "## Section 4: Train YOLOv11 OBB Model\n",
    "\n",
    "Configure and train the YOLOv11 OBB model with your dataset. Adjust hyperparameters as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0b68d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure training parameters\n",
    "EPOCHS = 100\n",
    "IMGSZ = 640\n",
    "BATCH_SIZE = 16\n",
    "DEVICE = 0  # GPU device (0 for first GPU, -1 for CPU)\n",
    "PATIENCE = 20  # Early stopping patience\n",
    "SAVE_DIR = \"runs/detect\"\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Image Size: {IMGSZ}\")\n",
    "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  Device: GPU {DEVICE}\" if DEVICE >= 0 else \"  Device: CPU\")\n",
    "print(f\"  Early Stopping Patience: {PATIENCE}\")\n",
    "print()\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "results = model.train(\n",
    "    data=DATA_YAML_PATH,\n",
    "    epochs=EPOCHS,\n",
    "    imgsz=IMGSZ,\n",
    "    batch=BATCH_SIZE,\n",
    "    device=DEVICE,\n",
    "    patience=PATIENCE,\n",
    "    save=True,\n",
    "    project=SAVE_DIR,\n",
    "    name=\"obb_model\",\n",
    "    verbose=True,\n",
    "    # Data augmentation parameters\n",
    "    augment=True,\n",
    "    mosaic=1.0,\n",
    "    flipud=0.5,\n",
    "    fliplr=0.5,\n",
    "    degrees=10,\n",
    "    translate=0.1,\n",
    "    scale=0.5,\n",
    "    hsv_h=0.015,\n",
    "    hsv_s=0.7,\n",
    "    hsv_v=0.4,\n",
    "    # Performance parameters\n",
    "    workers=8,\n",
    "    cache=True,\n",
    "    close_mosaic=10,\n",
    "    # Validation parameters\n",
    "    val=True,\n",
    "    save_json=False,\n",
    "    plots=True,\n",
    ")\n",
    "\n",
    "print(\"âœ“ Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c53607",
   "metadata": {},
   "source": [
    "## Section 5: Validate Trained Model\n",
    "\n",
    "Validate the trained model on the validation dataset and display performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3461208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best trained model\n",
    "BEST_MODEL_PATH = f\"{SAVE_DIR}/obb_model/weights/best.pt\"\n",
    "\n",
    "if Path(BEST_MODEL_PATH).exists():\n",
    "    best_model = YOLO(BEST_MODEL_PATH)\n",
    "    print(f\"âœ“ Loaded best model from {BEST_MODEL_PATH}\")\n",
    "    \n",
    "    # Validate the model\n",
    "    print(\"\\nValidating model on validation set...\")\n",
    "    val_results = best_model.val(\n",
    "        data=DATA_YAML_PATH,\n",
    "        imgsz=IMGSZ,\n",
    "        batch=BATCH_SIZE,\n",
    "        device=DEVICE,\n",
    "        verbose=True,\n",
    "    )\n",
    "    \n",
    "    print(\"\\nâœ“ Validation completed!\")\n",
    "    print(\"\\nValidation Metrics:\")\n",
    "    print(f\"  box_loss: {val_results.box.mean() if hasattr(val_results, 'box') else 'N/A'}\")\n",
    "    print(f\"  cls_loss: {val_results.cls.mean() if hasattr(val_results, 'cls') else 'N/A'}\")\n",
    "else:\n",
    "    print(f\"âš  Best model not found at {BEST_MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff31fde",
   "metadata": {},
   "source": [
    "## Section 6: Run Inference on Images/Videos\n",
    "\n",
    "Execute predictions on test images or videos using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761df5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure inference parameters\n",
    "SOURCE_PATH = \"path/to/test/image.jpg\"  # Change to your image or video path\n",
    "CONF_THRESHOLD = 0.25  # Confidence threshold for detections\n",
    "\n",
    "# Example: Using images from the validation set\n",
    "# Uncomment and modify the paths as needed\n",
    "# SOURCE_PATH = \"runs/detect/obb_model/val/images\"\n",
    "\n",
    "print(f\"Running inference on: {SOURCE_PATH}\")\n",
    "print(f\"Confidence threshold: {CONF_THRESHOLD}\")\n",
    "print()\n",
    "\n",
    "# Run inference\n",
    "if Path(BEST_MODEL_PATH).exists():\n",
    "    inference_results = best_model.predict(\n",
    "        source=SOURCE_PATH,\n",
    "        imgsz=IMGSZ,\n",
    "        device=DEVICE,\n",
    "        conf=CONF_THRESHOLD,\n",
    "        verbose=True,\n",
    "    )\n",
    "    \n",
    "    print(\"âœ“ Inference completed!\")\n",
    "    print(f\"Number of detections: {len(inference_results)}\")\n",
    "else:\n",
    "    print(\"âš  Model not available. Please train or load a model first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df27843",
   "metadata": {},
   "source": [
    "## Section 7: Visualize Results\n",
    "\n",
    "Display predicted bounding boxes, oriented boxes, confidence scores, and comparison plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677a179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training results plots\n",
    "RESULTS_DIR = Path(f\"{SAVE_DIR}/obb_model\")\n",
    "\n",
    "if RESULTS_DIR.exists():\n",
    "    # Display training metrics\n",
    "    metrics_files = list(RESULTS_DIR.glob(\"**/results*.csv\")) + list(RESULTS_DIR.glob(\"**/metrics*.png\"))\n",
    "    \n",
    "    print(\"Training Results Plots:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Display all .png files from the results directory\n",
    "    plot_files = list(RESULTS_DIR.rglob(\"*.png\"))\n",
    "    \n",
    "    if plot_files:\n",
    "        for plot_file in sorted(plot_files)[:10]:  # Display first 10 plots\n",
    "            try:\n",
    "                print(f\"\\nðŸ“Š {plot_file.name}\")\n",
    "                display(Image(str(plot_file)))\n",
    "            except Exception as e:\n",
    "                print(f\"Could not display {plot_file.name}: {e}\")\n",
    "    else:\n",
    "        print(\"No plots found in results directory.\")\n",
    "else:\n",
    "    print(\"âš  Results directory not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883599d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display inference results with detected OBBs\n",
    "print(\"\\nInference Results:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if 'inference_results' in locals():\n",
    "    for i, result in enumerate(inference_results[:5]):  # Display first 5 results\n",
    "        print(f\"\\nðŸ“· Result {i+1}\")\n",
    "        \n",
    "        # Display the result image if available\n",
    "        if result.plot() is not None:\n",
    "            # Plot shows detections with boxes\n",
    "            fig = plt.figure(figsize=(12, 8))\n",
    "            plt.imshow(result.plot()[..., ::-1])  # Convert BGR to RGB\n",
    "            plt.axis('off')\n",
    "            plt.title(f\"Detection Result {i+1}\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        # Print detection details\n",
    "        if hasattr(result, 'boxes'):\n",
    "            print(f\"  Detections: {len(result.boxes)}\")\n",
    "            for box in result.boxes:\n",
    "                if hasattr(box, 'obb'):\n",
    "                    print(f\"    - OBB: {box.obb}, Confidence: {box.conf:.3f}\")\n",
    "                else:\n",
    "                    print(f\"    - Box: {box.xyxy}, Confidence: {box.conf:.3f}\")\n",
    "else:\n",
    "    print(\"âš  No inference results available. Please run inference first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b26d2fa",
   "metadata": {},
   "source": [
    "## Section 8: Download and Export Results\n",
    "\n",
    "Export the trained model and results for use outside Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3209b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colab: Download trained model and results\n",
    "import shutil\\n\\nMODEL_DIR = Path(f\"{SAVE_DIR}/obb_model/weights\\\")\\n\\nif MODEL_DIR.exists():\\n    print(\\\"Available model files:\\\")\\n    for model_file in MODEL_DIR.glob(\\\"*.pt\\\"):\\n        file_size = model_file.stat().st_size / (1024 * 1024)  # Convert to MB\\n        print(f\\\"  - {model_file.name} ({file_size:.1f} MB)\\\")\\n    \\n    # Create a zip file with all results\\n    print(\\\"\\\\nCreating zip file with training results...\\\")\\n    try:\\n        shutil.make_archive(\\n            'obb_model_results',\\n            'zip',\\n            f\\\"{SAVE_DIR}/obb_model\\\"\\n        )\\n        print(\\\"âœ“ Created obb_model_results.zip\\\")\\n        print(\\\"  You can download this file from Colab Files panel\\\")\\n    except Exception as e:\\n        print(f\\\"Could not create zip: {e}\\\")\\nelse:\\n    print(\\\"âš  Model directory not found\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ff0e2d",
   "metadata": {},
   "source": [
    "## Section 9: Utility Functions\n",
    "\n",
    "Helper functions for common tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af5d7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\\n    \\\"\\\"\\\"\\n    Load a trained YOLOv11 OBB model.\\n    \\n    Args:\\n        model_path: Path to the model weights file\\n    \\n    Returns:\\n        Loaded YOLO model\\n    \\\"\\\"\\\"\\n    if Path(model_path).exists():\\n        print(f\\\"Loading model from {model_path}...\\\")\\n        model = YOLO(model_path)\\n        print(\\\"âœ“ Model loaded successfully!\\\")\\n        return model\\n    else:\\n        print(f\\\"Error: Model not found at {model_path}\\\")\\n        return None\\n\\n\\ndef run_batch_inference(model, image_dir, conf=0.25):\\n    \\\"\\\"\\\"\\n    Run inference on all images in a directory.\\n    \\n    Args:\\n        model: YOLO model object\\n        image_dir: Directory containing images\\n        conf: Confidence threshold\\n    \\n    Returns:\\n        List of detection results\\n    \\\"\\\"\\\"\\n    print(f\\\"Running inference on images in {image_dir}...\\\")\\n    results = model.predict(\\n        source=image_dir,\\n        imgsz=IMGSZ,\\n        device=DEVICE,\\n        conf=conf,\\n        verbose=True\\n    )\\n    print(f\\\"âœ“ Inference completed! Processed {len(results)} images\\\")\\n    return results\\n\\n\\ndef export_model(model, export_format=\\\"onnx\\\"):\\n    \\\"\\\"\\\"\\n    Export the model to different formats.\\n    \\n    Supported formats: torchscript, onnx, openvino, tflite, pb, saved_model, rknn\\n    \\n    Args:\\n        model: YOLO model object\\n        export_format: Export format\\n    \\n    Returns:\\n        Path to exported model\\n    \\\"\\\"\\\"\\n    print(f\\\"Exporting model to {export_format.upper()}...\\\")\\n    try:\\n        exported_path = model.export(format=export_format)\\n        print(f\\\"âœ“ Model exported to {exported_path}\\\")\\n        return exported_path\\n    except Exception as e:\\n        print(f\\\"Error exporting model: {e}\\\")\\n        return None\\n\\nprint(\\\"âœ“ Utility functions defined successfully!\\\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
